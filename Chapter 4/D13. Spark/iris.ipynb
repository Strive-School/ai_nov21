{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark\n",
    "\n",
    "In the same way that for many programs hellow word is the first program in spark is computing pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.14154708\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "NUM_SAMPLES = 100000000\n",
    "def inside(p):\n",
    " x, y = random.random(), random.random()\n",
    " return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, NUM_SAMPLES)).filter(inside).count()\n",
    "pi = 4 * count / NUM_SAMPLES\n",
    "print(\"Pi is roughly\", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL and DataFrames\n",
    "\n",
    "There are two approaches to Spark, the DataFrame approach and the RDD approach. We are going to learn the SQL approach since it is works in the way spark intends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "Spark needs to use a session in order to process data in a parallel way.\n",
    "\n",
    "A session can be built in many different ways, what is going to be a difference maker for most local machines is that we need to specify to spark to either get it or create it.\n",
    "\n",
    "We will use this session to define our Spark DataFrames.\n",
    "\n",
    "When Creating DataFrames we can let spark infer the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create our own schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sepal_length: double (nullable = true)\n",
      " |-- sepal_width: double (nullable = true)\n",
      " |-- petal_length: double (nullable = true)\n",
      " |-- petal_width: double (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Spark doesn`t need the X and Y separated in the standard format.\n",
    "\n",
    "As you will see throught the notebook spark will directly operate on the DataFrame after specifying an input and aoutput column.\n",
    "\n",
    "By default Spark takes a column called deatures as the input in all classifiers and the Y column is called labels\n",
    "\n",
    "We can create the  feature column by using a vector assembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+-----------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|  type|         features|\n",
      "+------------+-----------+------------+-----------+------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Setosa|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2|Setosa|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2|Setosa|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2|Setosa|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2|Setosa|[5.0,3.6,1.4,0.2]|\n",
      "|         5.4|        3.9|         1.7|        0.4|Setosa|[5.4,3.9,1.7,0.4]|\n",
      "|         4.6|        3.4|         1.4|        0.3|Setosa|[4.6,3.4,1.4,0.3]|\n",
      "|         5.0|        3.4|         1.5|        0.2|Setosa|[5.0,3.4,1.5,0.2]|\n",
      "|         4.4|        2.9|         1.4|        0.2|Setosa|[4.4,2.9,1.4,0.2]|\n",
      "|         4.9|        3.1|         1.5|        0.1|Setosa|[4.9,3.1,1.5,0.1]|\n",
      "|         5.4|        3.7|         1.5|        0.2|Setosa|[5.4,3.7,1.5,0.2]|\n",
      "|         4.8|        3.4|         1.6|        0.2|Setosa|[4.8,3.4,1.6,0.2]|\n",
      "|         4.8|        3.0|         1.4|        0.1|Setosa|[4.8,3.0,1.4,0.1]|\n",
      "|         4.3|        3.0|         1.1|        0.1|Setosa|[4.3,3.0,1.1,0.1]|\n",
      "|         5.8|        4.0|         1.2|        0.2|Setosa|[5.8,4.0,1.2,0.2]|\n",
      "|         5.7|        4.4|         1.5|        0.4|Setosa|[5.7,4.4,1.5,0.4]|\n",
      "|         5.4|        3.9|         1.3|        0.4|Setosa|[5.4,3.9,1.3,0.4]|\n",
      "|         5.1|        3.5|         1.4|        0.3|Setosa|[5.1,3.5,1.4,0.3]|\n",
      "|         5.7|        3.8|         1.7|        0.3|Setosa|[5.7,3.8,1.7,0.3]|\n",
      "|         5.1|        3.8|         1.5|        0.3|Setosa|[5.1,3.8,1.5,0.3]|\n",
      "+------------+-----------+------------+-----------+------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numericCols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "We can use a string indexes in the same way as the vector assembler to ordinally encode our types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+-----------------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|  type|         features|labelIndex|\n",
      "+------------+-----------+------------+-----------+------+-----------------+----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Setosa|[5.1,3.5,1.4,0.2]|       0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|Setosa|[4.9,3.0,1.4,0.2]|       0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|Setosa|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|Setosa|[4.6,3.1,1.5,0.2]|       0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|Setosa|[5.0,3.6,1.4,0.2]|       0.0|\n",
      "|         5.4|        3.9|         1.7|        0.4|Setosa|[5.4,3.9,1.7,0.4]|       0.0|\n",
      "|         4.6|        3.4|         1.4|        0.3|Setosa|[4.6,3.4,1.4,0.3]|       0.0|\n",
      "|         5.0|        3.4|         1.5|        0.2|Setosa|[5.0,3.4,1.5,0.2]|       0.0|\n",
      "|         4.4|        2.9|         1.4|        0.2|Setosa|[4.4,2.9,1.4,0.2]|       0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1|Setosa|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "+------------+-----------+------------+-----------+------+-----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split\n",
    "\n",
    "Spark Dataframes come pre-equipped with a random split function that will give you as many portions as specified.\n",
    "\n",
    "The proportions for each portion are passed in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "Many Spark classifiers unfortunatelly do not handle good multylabel classification so be very carefull with which you choose.\n",
    "\n",
    "they can all be found here: https://spark.apache.org/docs/latest/ml-classification-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying input and target\n",
    "\n",
    "As I said the default names are features an label, but we can also specify them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "It is done in the same way as SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "    \n",
    "This part is a little different. Spark will not output a prediction vector, it will direclty add a column to the DataFrame.\n",
    "\n",
    "To predict we call the method 'transform' from the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting\n",
    "\n",
    "This structures are built to be parallelized in the CPU so we cannot access them in a standard fashion.\n",
    "\n",
    "To get a subset of columns we need to use select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+----------+--------------------+----------+--------------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|labelIndex|       rawPrediction|prediction|         probability|\n",
      "+------------+-----------+------------+-----------+----------+--------------------+----------+--------------------+\n",
      "|         4.3|        3.0|         1.1|        0.1|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         4.5|        2.3|         1.3|        0.3|       0.0|      [19.0,0.0,1.0]|       0.0|     [0.95,0.0,0.05]|\n",
      "|         4.6|        3.6|         1.0|        0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         4.9|        3.1|         1.5|        0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         4.9|        3.6|         1.4|        0.1|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.0|        3.4|         1.6|        0.4|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|         5.0|        3.5|         1.3|        0.3|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.0|        3.5|         1.6|        0.6|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|         5.1|        3.3|         1.7|        0.5|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|         5.1|        3.5|         1.4|        0.3|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.1|        3.7|         1.5|        0.4|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|         5.1|        3.8|         1.6|        0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.2|        3.4|         1.4|        0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.4|        3.7|         1.5|        0.2|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.4|        3.9|         1.3|        0.4|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|         5.5|        2.4|         3.7|        1.0|       1.0|      [0.0,20.0,0.0]|       1.0|       [0.0,1.0,0.0]|\n",
      "|         5.6|        2.7|         4.2|        1.3|       1.0|      [0.0,20.0,0.0]|       1.0|       [0.0,1.0,0.0]|\n",
      "|         5.6|        2.8|         4.9|        2.0|       2.0|[0.0,2.0714285714...|       2.0|[0.0,0.1035714285...|\n",
      "|         5.6|        2.9|         3.6|        1.3|       1.0|      [0.0,20.0,0.0]|       1.0|       [0.0,1.0,0.0]|\n",
      "|         5.7|        2.5|         5.0|        2.0|       2.0|[0.0,2.0714285714...|       2.0|[0.0,0.1035714285...|\n",
      "|         5.7|        3.8|         1.7|        0.3|       0.0|      [20.0,0.0,0.0]|       0.0|       [1.0,0.0,0.0]|\n",
      "|         5.7|        4.4|         1.5|        0.4|       0.0|      [19.0,1.0,0.0]|       0.0|     [0.95,0.05,0.0]|\n",
      "|         5.8|        2.7|         4.1|        1.0|       1.0|[0.0,19.947368421...|       1.0|[0.0,0.9973684210...|\n",
      "|         5.9|        3.2|         4.8|        1.8|       1.0|[0.0,1.0714285714...|       2.0|[0.0,0.0535714285...|\n",
      "|         6.0|        3.0|         4.8|        1.8|       2.0|[0.0,1.0714285714...|       2.0|[0.0,0.0535714285...|\n",
      "+------------+-----------+------------+-----------+----------+--------------------+----------+--------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|labelIndex|prediction|\n",
      "+----------+----------+\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       0.0|\n",
      "+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "\n",
    "In a very familiar format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9754807071880243\n",
      "Test Error = 0.024519292811975735\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
